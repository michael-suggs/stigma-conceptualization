{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('anaconda3-2020.11': pyenv)"
  },
  "interpreter": {
   "hash": "a0f0fbbf2742dfdc4e6a359a9f9039ee6f84d9c065f1ededfc37f065425179fb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Stigma Cue Prediction -- Neural Networks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization, Conv1D, Dense, Dropout, Embedding, Flatten, GlobalMaxPooling1D, Input, LeakyReLU, LSTM\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot, text_to_word_sequence, Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.regularizers import l1_l2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "source": [
    "## Data Preparation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   Stig_c1  Stig_c2  Stig_c3  Stig_c4  Stig_c5  Challn_c1  \\\n",
       "ID                                                                          \n",
       "Submission lwgnzw      1.0      0.0      1.0      0.0      0.0        0.0   \n",
       "Comment gph9dfy        0.0      0.0      0.0      0.0      0.0        0.0   \n",
       "Comment gpi5kze        0.0      0.0      0.0      0.0      0.0        0.0   \n",
       "Submission lwgo4f      0.0      0.0      1.0      0.0      1.0        0.0   \n",
       "Comment gph9zt7        0.0      0.0      0.0      0.0      0.0        1.0   \n",
       "...                    ...      ...      ...      ...      ...        ...   \n",
       "Submission lxe14g      0.0      0.0      1.0      1.0      0.0        0.0   \n",
       "Submission lxe1p5      0.0      0.0      1.0      1.0      0.0        0.0   \n",
       "Submission lxe5js      1.0      0.0      0.0      1.0      1.0        0.0   \n",
       "Submission lxe6ea      0.0      0.0      0.0      1.0      0.0        0.0   \n",
       "Submission lxe6h4      1.0      0.0      1.0      0.0      1.0        0.0   \n",
       "\n",
       "                   Challn_c2  Challn_c3  Challn_c4  Challn_c5  \n",
       "ID                                                             \n",
       "Submission lwgnzw        0.0        0.0        0.0        0.0  \n",
       "Comment gph9dfy          0.0        1.0        0.0        0.0  \n",
       "Comment gpi5kze          0.0        1.0        0.0        0.0  \n",
       "Submission lwgo4f        0.0        0.0        0.0        0.0  \n",
       "Comment gph9zt7          0.0        0.0        0.0        0.0  \n",
       "...                      ...        ...        ...        ...  \n",
       "Submission lxe14g        0.0        0.0        0.0        0.0  \n",
       "Submission lxe1p5        0.0        0.0        0.0        0.0  \n",
       "Submission lxe5js        0.0        0.0        0.0        0.0  \n",
       "Submission lxe6ea        0.0        0.0        0.0        0.0  \n",
       "Submission lxe6h4        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[573 rows x 10 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Stig_c1</th>\n      <th>Stig_c2</th>\n      <th>Stig_c3</th>\n      <th>Stig_c4</th>\n      <th>Stig_c5</th>\n      <th>Challn_c1</th>\n      <th>Challn_c2</th>\n      <th>Challn_c3</th>\n      <th>Challn_c4</th>\n      <th>Challn_c5</th>\n    </tr>\n    <tr>\n      <th>ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Submission lwgnzw</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Comment gph9dfy</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Comment gpi5kze</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Submission lwgo4f</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Comment gph9zt7</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Submission lxe14g</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Submission lxe1p5</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Submission lxe5js</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Submission lxe6ea</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Submission lxe6h4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>573 rows × 10 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "data = pd.read_csv('../data/output/20210302T19:23:10_stigma.csv', index_col='ID')\n",
    "data = data.replace(-1.0, np.NaN).dropna(how='all').fillna(0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../data/input/2021-03-02T19:23:10/new_submissions.csv', index_col='id')\n",
    "com = pd.read_csv('../data/input/2021-03-02T19:23:10/new_comments.csv', index_col='id')\n",
    "\n",
    "subids = data.index.str.extract(r'Submission (.*)').dropna()\n",
    "comids = data.index.str.extract(r'Comment (.*)').dropna()\n",
    "\n",
    "sub = sub.loc[subids[0],:].rename(columns={'selftext': 'body'})\n",
    "sub.index = 'Submission ' + sub.index\n",
    "com = com.loc[comids[0],:]\n",
    "com.index = 'Comment ' + com.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                                body  Stig_c1  \\\n",
       "ID                                                                              \n",
       "Submission lwgnzw  I really want to die, I feel like there’s noth...      1.0   \n",
       "Comment gph9dfy    Please do not do what ever you are about to do...      0.0   \n",
       "Comment gpi5kze            me and big pepper are here to talk to you      0.0   \n",
       "Submission lwgo4f  I'm in year 11 but my entire high school atten...      0.0   \n",
       "Comment gph9zt7    if there is a downhill in life there always mu...      0.0   \n",
       "...                                                              ...      ...   \n",
       "Submission lxe14g  I went to the attic last night. There was a be...      0.0   \n",
       "Submission lxe1p5  I seriously need someome to talk to. I have pl...      0.0   \n",
       "Submission lxe5js  I heard this phrase in this show the other day...      1.0   \n",
       "Submission lxe6ea  She said she hasn’t cut in 3 years, and recent...      0.0   \n",
       "Submission lxe6h4  I am so incredibly alone in adulthood. \\n\\nNo ...      1.0   \n",
       "\n",
       "                   Stig_c2  Stig_c3  Stig_c4  Stig_c5  Challn_c1  Challn_c2  \\\n",
       "ID                                                                            \n",
       "Submission lwgnzw      0.0      1.0      0.0      0.0        0.0        0.0   \n",
       "Comment gph9dfy        0.0      0.0      0.0      0.0        0.0        0.0   \n",
       "Comment gpi5kze        0.0      0.0      0.0      0.0        0.0        0.0   \n",
       "Submission lwgo4f      0.0      1.0      0.0      1.0        0.0        0.0   \n",
       "Comment gph9zt7        0.0      0.0      0.0      0.0        1.0        0.0   \n",
       "...                    ...      ...      ...      ...        ...        ...   \n",
       "Submission lxe14g      0.0      1.0      1.0      0.0        0.0        0.0   \n",
       "Submission lxe1p5      0.0      1.0      1.0      0.0        0.0        0.0   \n",
       "Submission lxe5js      0.0      0.0      1.0      1.0        0.0        0.0   \n",
       "Submission lxe6ea      0.0      0.0      1.0      0.0        0.0        0.0   \n",
       "Submission lxe6h4      0.0      1.0      0.0      1.0        0.0        0.0   \n",
       "\n",
       "                   Challn_c3  Challn_c4  Challn_c5  \n",
       "ID                                                  \n",
       "Submission lwgnzw        0.0        0.0        0.0  \n",
       "Comment gph9dfy          1.0        0.0        0.0  \n",
       "Comment gpi5kze          1.0        0.0        0.0  \n",
       "Submission lwgo4f        0.0        0.0        0.0  \n",
       "Comment gph9zt7          0.0        0.0        0.0  \n",
       "...                      ...        ...        ...  \n",
       "Submission lxe14g        0.0        0.0        0.0  \n",
       "Submission lxe1p5        0.0        0.0        0.0  \n",
       "Submission lxe5js        0.0        0.0        0.0  \n",
       "Submission lxe6ea        0.0        0.0        0.0  \n",
       "Submission lxe6h4        0.0        0.0        0.0  \n",
       "\n",
       "[568 rows x 11 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>body</th>\n      <th>Stig_c1</th>\n      <th>Stig_c2</th>\n      <th>Stig_c3</th>\n      <th>Stig_c4</th>\n      <th>Stig_c5</th>\n      <th>Challn_c1</th>\n      <th>Challn_c2</th>\n      <th>Challn_c3</th>\n      <th>Challn_c4</th>\n      <th>Challn_c5</th>\n    </tr>\n    <tr>\n      <th>ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Submission lwgnzw</th>\n      <td>I really want to die, I feel like there’s noth...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Comment gph9dfy</th>\n      <td>Please do not do what ever you are about to do...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Comment gpi5kze</th>\n      <td>me and big pepper are here to talk to you</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Submission lwgo4f</th>\n      <td>I'm in year 11 but my entire high school atten...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Comment gph9zt7</th>\n      <td>if there is a downhill in life there always mu...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Submission lxe14g</th>\n      <td>I went to the attic last night. There was a be...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Submission lxe1p5</th>\n      <td>I seriously need someome to talk to. I have pl...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Submission lxe5js</th>\n      <td>I heard this phrase in this show the other day...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Submission lxe6ea</th>\n      <td>She said she hasn’t cut in 3 years, and recent...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Submission lxe6h4</th>\n      <td>I am so incredibly alone in adulthood. \\n\\nNo ...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>568 rows × 11 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "subcom = pd.concat([sub, com], axis=0).loc[data.index,:][['body']]\n",
    "full_data = subcom.join(data).dropna()\n",
    "full_data"
   ]
  },
  {
   "source": [
    "### Splitting and Binarizing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "y_train:\n[[0 1 0 ... 0 0 0]\n [1 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 1 0 ... 0 0 0]\n [0 0 0 ... 0 0 1]\n [0 1 0 ... 0 0 0]]\n\nMLB Classes:\n['Challn_c1', 'Challn_c2', 'Challn_c3', 'Challn_c4', 'Challn_c5', 'Stig_c1', 'Stig_c2', 'Stig_c3', 'Stig_c4', 'Stig_c5']\n"
     ]
    }
   ],
   "source": [
    "X = full_data.body\n",
    "y = full_data.drop('body', axis=1)\n",
    "y = y.apply(lambda r: list(y.columns[r.astype(bool)]), axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "mlb = MultiLabelBinarizer().fit([list(data.columns)])\n",
    "y_train = mlb.transform(y_train)\n",
    "y_test = mlb.transform(y_test)\n",
    "\n",
    "print(f'y_train:\\n{y_train}', end='\\n\\n')\n",
    "print('MLB Classes:')\n",
    "print(list(mlb.classes_), sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Max Length: 1134\nNum Words:  5053\n\nX: (454,)  | (114,)\ny: (454, 10) | (114, 10)\n"
     ]
    }
   ],
   "source": [
    "max_length = max(X.str.split().map(len))\n",
    "num_words = len(set(X.str.replace(r'[^a-zA-Z\\s]', '').str.replace(r'\\n', ' ').str.lower().str.split(' ').sum()))\n",
    "\n",
    "print(f'Max Length: {max_length}\\nNum Words:  {num_words}\\n')\n",
    "print(f'X: {X_train.shape}  | {X_test.shape}\\ny: {y_train.shape} | {y_test.shape}')"
   ]
  },
  {
   "source": [
    "## Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.00001\n",
    "\n",
    "def standard_sequential(model_name: str, input_shape, output_shape=len(mlb.classes_)):\n",
    "    \"\"\"Standardized model architecture for comparing techniques (eg, embeddings)\"\"\"\n",
    "    model = Sequential(name=model_name)\n",
    "    model.add(Input(shape=input_shape))\n",
    "    # model.add(Embedding(input_dim=X_train_tokens.shape[1], output_dim=200))\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    # model.add(Conv1D(32, 11, activation='relu'))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    # model.add(Conv1D(64, 7, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(output_shape, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def run_model(model, Xtr, Xts, ytr=y_train, yts=y_test):\n",
    "    \"\"\"Fits and evaluates a given model, printing metrics and returning the history and predictions.\"\"\"\n",
    "    hist = model.fit(Xtr, ytr, epochs=EPOCHS, verbose=True, validation_data=(Xts, yts), batch_size=BATCH_SIZE)\n",
    "    y_pred = sequential_tokenized.predict(Xts)\n",
    "\n",
    "    print(sequential_tokenized.evaluate(Xts, yts))\n",
    "    print(confusion_matrix(yts, y_pred))\n",
    "    print(classification_report(yts, y_pred))\n",
    "\n",
    "    return hist, y_pred"
   ]
  },
  {
   "source": [
    "### Sequential -- Count Vectorized"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X: (454, 53167)  | (114, 53167)\ny: (454, 10) | (114, 10)\n"
     ]
    }
   ],
   "source": [
    "counts = CountVectorizer(stop_words='english', strip_accents='ascii', ngram_range=(1,3))\n",
    "counts.fit(X)\n",
    "X_train_vec = counts.transform(X_train)\n",
    "X_test_vec = counts.transform(X_test)\n",
    "\n",
    "X_train_vec.sort_indices()\n",
    "X_test_vec.sort_indices()\n",
    "\n",
    "print(f'X: {X_train_vec.shape}  | {X_test_vec.shape}\\ny: {y_train.shape} | {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_counts\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 1000)              53168000  \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 1000)              4000      \n_________________________________________________________________\nleaky_re_lu (LeakyReLU)      (None, 1000)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 500)               500500    \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 500)               2000      \n_________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)    (None, 500)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 100)               50100     \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 100)               400       \n_________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)    (None, 100)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 10)                1010      \n=================================================================\nTotal params: 53,726,010\nTrainable params: 53,722,810\nNon-trainable params: 3,200\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequential_counts = Sequential(name='sequential_counts')\n",
    "sequential_counts.add(Input(shape=X_train_vec.shape[1]))\n",
    "# sequential_counts.add(Embedding(input_dim=X_train_tokens.shape[1], output_dim=200))\n",
    "sequential_counts.add(Dense(1000))\n",
    "sequential_counts.add(BatchNormalization())\n",
    "sequential_counts.add(LeakyReLU())\n",
    "# sequential_counts.add(Conv1D(32, 11, activation='relu'))\n",
    "sequential_counts.add(Dense(500))\n",
    "sequential_counts.add(BatchNormalization())\n",
    "sequential_counts.add(LeakyReLU())\n",
    "# sequential_counts.add(Conv1D(64, 7, activation='relu'))\n",
    "sequential_counts.add(Dense(100))\n",
    "sequential_counts.add(BatchNormalization())\n",
    "sequential_counts.add(LeakyReLU())\n",
    "sequential_counts.add(Dense(len(mlb.classes_), activation='sigmoid'))\n",
    "\n",
    "sequential_counts.compile(\n",
    "    loss=BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=Nadam(learning_rate=0.0001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "sequential_counts.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - 13s 745ms/step - loss: 0.7913 - accuracy: 0.1013 - val_loss: 0.6952 - val_accuracy: 0.1053\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 10s 697ms/step - loss: 0.5661 - accuracy: 0.6370 - val_loss: 0.6926 - val_accuracy: 0.0789\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 10s 700ms/step - loss: 0.4706 - accuracy: 0.7007 - val_loss: 0.6862 - val_accuracy: 0.0877\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 11s 712ms/step - loss: 0.4252 - accuracy: 0.7225 - val_loss: 0.6784 - val_accuracy: 0.0965\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 11s 712ms/step - loss: 0.3996 - accuracy: 0.7812 - val_loss: 0.6703 - val_accuracy: 0.0877\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 11s 717ms/step - loss: 0.3746 - accuracy: 0.8012 - val_loss: 0.6604 - val_accuracy: 0.1053\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 11s 730ms/step - loss: 0.3434 - accuracy: 0.7796 - val_loss: 0.6511 - val_accuracy: 0.1228\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 11s 720ms/step - loss: 0.3212 - accuracy: 0.7737 - val_loss: 0.6406 - val_accuracy: 0.1579\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 11s 739ms/step - loss: 0.3020 - accuracy: 0.7382 - val_loss: 0.6314 - val_accuracy: 0.1930\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 11s 720ms/step - loss: 0.2877 - accuracy: 0.7668 - val_loss: 0.6192 - val_accuracy: 0.2456\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 11s 720ms/step - loss: 0.2821 - accuracy: 0.7665 - val_loss: 0.6086 - val_accuracy: 0.2807\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 11s 727ms/step - loss: 0.2734 - accuracy: 0.7776 - val_loss: 0.5987 - val_accuracy: 0.3070\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 11s 737ms/step - loss: 0.2575 - accuracy: 0.7768 - val_loss: 0.5889 - val_accuracy: 0.3158\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 11s 740ms/step - loss: 0.2426 - accuracy: 0.7764 - val_loss: 0.5799 - val_accuracy: 0.3333\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 11s 760ms/step - loss: 0.2288 - accuracy: 0.7967 - val_loss: 0.5707 - val_accuracy: 0.3421\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 11s 730ms/step - loss: 0.2308 - accuracy: 0.7812 - val_loss: 0.5631 - val_accuracy: 0.3596\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 11s 723ms/step - loss: 0.2169 - accuracy: 0.7806 - val_loss: 0.5541 - val_accuracy: 0.3684\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 11s 730ms/step - loss: 0.2063 - accuracy: 0.7511 - val_loss: 0.5474 - val_accuracy: 0.3596\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 11s 748ms/step - loss: 0.2061 - accuracy: 0.7607 - val_loss: 0.5379 - val_accuracy: 0.3860\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 11s 728ms/step - loss: 0.1943 - accuracy: 0.7628 - val_loss: 0.5293 - val_accuracy: 0.3860\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 11s 750ms/step - loss: 0.1982 - accuracy: 0.8062 - val_loss: 0.5232 - val_accuracy: 0.3684\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 11s 738ms/step - loss: 0.1790 - accuracy: 0.7861 - val_loss: 0.5165 - val_accuracy: 0.3596\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 11s 735ms/step - loss: 0.1786 - accuracy: 0.7855 - val_loss: 0.5082 - val_accuracy: 0.3596\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 11s 719ms/step - loss: 0.1678 - accuracy: 0.7803 - val_loss: 0.5022 - val_accuracy: 0.3596\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 11s 737ms/step - loss: 0.1652 - accuracy: 0.7951 - val_loss: 0.4962 - val_accuracy: 0.3509\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 11s 736ms/step - loss: 0.1616 - accuracy: 0.7482 - val_loss: 0.4915 - val_accuracy: 0.3684\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 11s 734ms/step - loss: 0.1597 - accuracy: 0.7792 - val_loss: 0.4826 - val_accuracy: 0.3684\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 11s 712ms/step - loss: 0.1556 - accuracy: 0.7738 - val_loss: 0.4773 - val_accuracy: 0.3596\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 11s 724ms/step - loss: 0.1525 - accuracy: 0.7694 - val_loss: 0.4717 - val_accuracy: 0.3947\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 11s 723ms/step - loss: 0.1423 - accuracy: 0.7861 - val_loss: 0.4676 - val_accuracy: 0.3772\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 11s 710ms/step - loss: 0.1352 - accuracy: 0.8100 - val_loss: 0.4647 - val_accuracy: 0.3596\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 11s 719ms/step - loss: 0.1284 - accuracy: 0.7479 - val_loss: 0.4597 - val_accuracy: 0.3509\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 11s 722ms/step - loss: 0.1301 - accuracy: 0.7915 - val_loss: 0.4566 - val_accuracy: 0.3947\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 11s 765ms/step - loss: 0.1260 - accuracy: 0.8073 - val_loss: 0.4496 - val_accuracy: 0.3860\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 11s 721ms/step - loss: 0.1190 - accuracy: 0.7659 - val_loss: 0.4455 - val_accuracy: 0.3860\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 11s 712ms/step - loss: 0.1173 - accuracy: 0.7665 - val_loss: 0.4414 - val_accuracy: 0.3772\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 11s 704ms/step - loss: 0.1191 - accuracy: 0.8019 - val_loss: 0.4385 - val_accuracy: 0.3772\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 11s 706ms/step - loss: 0.1120 - accuracy: 0.7513 - val_loss: 0.4322 - val_accuracy: 0.3509\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 10s 699ms/step - loss: 0.1066 - accuracy: 0.7629 - val_loss: 0.4299 - val_accuracy: 0.3509\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 10s 691ms/step - loss: 0.1113 - accuracy: 0.7849 - val_loss: 0.4250 - val_accuracy: 0.3596\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 10s 680ms/step - loss: 0.1060 - accuracy: 0.7719 - val_loss: 0.4215 - val_accuracy: 0.3860\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 10s 678ms/step - loss: 0.0992 - accuracy: 0.7644 - val_loss: 0.4218 - val_accuracy: 0.3772\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 10s 686ms/step - loss: 0.1040 - accuracy: 0.7752 - val_loss: 0.4191 - val_accuracy: 0.3772\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 10s 680ms/step - loss: 0.0999 - accuracy: 0.7928 - val_loss: 0.4153 - val_accuracy: 0.3860\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 10s 684ms/step - loss: 0.0911 - accuracy: 0.7621 - val_loss: 0.4121 - val_accuracy: 0.3860\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 10s 686ms/step - loss: 0.0905 - accuracy: 0.7828 - val_loss: 0.4091 - val_accuracy: 0.3860\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 10s 685ms/step - loss: 0.0921 - accuracy: 0.7909 - val_loss: 0.4054 - val_accuracy: 0.3860\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 10s 689ms/step - loss: 0.0905 - accuracy: 0.7906 - val_loss: 0.4010 - val_accuracy: 0.3947\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 10s 692ms/step - loss: 0.0835 - accuracy: 0.7337 - val_loss: 0.4006 - val_accuracy: 0.3860\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 11s 740ms/step - loss: 0.0820 - accuracy: 0.7821 - val_loss: 0.3986 - val_accuracy: 0.3947\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.3947\n",
      "[0.3985540270805359, 0.3947368562221527]\n"
     ]
    }
   ],
   "source": [
    "hist = sequential_counts.fit(X_train_vec, y_train, epochs=50, verbose=True, validation_data=(X_test_vec, y_test), batch_size=32)\n",
    "y_pred = sequential_counts.predict(X_test_vec)\n",
    "\n",
    "print(sequential_counts.evaluate(X_test_vec, y_test))\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "source": [
    "### Sequential -- Tokenized"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X Train: (454, 1134)\nX Test:  (114, 1134)\n"
     ]
    }
   ],
   "source": [
    "# X_train_tokens = X_train.apply(lambda r: text_to_word_sequence(r))\n",
    "# X_test_tokens = X_test.apply(lambda r: text_to_word_sequence(r))\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words + 1)\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "# X_train_tokens = tokenizer.texts_to_matrix(X_train, mode='count')\n",
    "# X_test_tokens = tokenizer.texts_to_matrix(X_test, mode='count')\n",
    "\n",
    "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_tokens = pad_sequences(X_train_tokens, maxlen=max_length, padding='post')\n",
    "\n",
    "X_test_tokens = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_tokens = pad_sequences(X_test_tokens, maxlen=max_length, padding='post')\n",
    "\n",
    "print(f'X Train: {X_train_tokens.shape}')\n",
    "print(f'X Test:  {X_test_tokens.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5220"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_tokenized\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_9 (Embedding)      (None, 1134, 200)         1044200   \n_________________________________________________________________\nglobal_max_pooling1d_9 (Glob (None, 200)               0         \n_________________________________________________________________\ndense_27 (Dense)             (None, 250)               50250     \n_________________________________________________________________\nbatch_normalization_24 (Batc (None, 250)               1000      \n_________________________________________________________________\nleaky_re_lu_24 (LeakyReLU)   (None, 250)               0         \n_________________________________________________________________\ndense_28 (Dense)             (None, 10)                2510      \n=================================================================\nTotal params: 1,097,960\nTrainable params: 1,097,460\nNon-trainable params: 500\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequential_tokenized = Sequential(name='sequential_tokenized')\n",
    "sequential_tokenized.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=200, input_length=max_length))\n",
    "sequential_tokenized.add(GlobalMaxPooling1D())\n",
    "# sequential_tokenized.add(Dense(1000))\n",
    "# sequential_tokenized.add(BatchNormalization())\n",
    "# sequential_tokenized.add(LeakyReLU())\n",
    "# sequential_tokenized.add(Dense(500))\n",
    "# sequential_tokenized.add(BatchNormalization())\n",
    "# sequential_tokenized.add(LeakyReLU())\n",
    "sequential_tokenized.add(Dense(250))\n",
    "sequential_tokenized.add(BatchNormalization())\n",
    "sequential_tokenized.add(LeakyReLU())\n",
    "# sequential_tokenized.add(Dense(100))\n",
    "# sequential_tokenized.add(BatchNormalization())\n",
    "# sequential_tokenized.add(LeakyReLU())\n",
    "# sequential_tokenized.add(Dense(50))\n",
    "# sequential_tokenized.add(BatchNormalization())\n",
    "# sequential_tokenized.add(LeakyReLU())\n",
    "sequential_tokenized.add(Dense(len(mlb.classes_), activation='sigmoid'))\n",
    "\n",
    "sequential_tokenized.compile(\n",
    "    loss=BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=Nadam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "sequential_tokenized.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 0.6703 - accuracy: 0.1510 - val_loss: 0.6179 - val_accuracy: 0.0088\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.4588 - accuracy: 0.4448 - val_loss: 0.5213 - val_accuracy: 0.2719\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.2998 - accuracy: 0.5044 - val_loss: 0.4875 - val_accuracy: 0.2895\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.2190 - accuracy: 0.6134 - val_loss: 0.4753 - val_accuracy: 0.3509\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.1557 - accuracy: 0.6729 - val_loss: 0.4453 - val_accuracy: 0.3684\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.1113 - accuracy: 0.7417 - val_loss: 0.4357 - val_accuracy: 0.3947\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0887 - accuracy: 0.7331 - val_loss: 0.4228 - val_accuracy: 0.4474\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0631 - accuracy: 0.7488 - val_loss: 0.4000 - val_accuracy: 0.4298\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0435 - accuracy: 0.7629 - val_loss: 0.3814 - val_accuracy: 0.4386\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0345 - accuracy: 0.7823 - val_loss: 0.3720 - val_accuracy: 0.4474\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0241 - accuracy: 0.7614 - val_loss: 0.3414 - val_accuracy: 0.4474\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0221 - accuracy: 0.7712 - val_loss: 0.3362 - val_accuracy: 0.4035\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0159 - accuracy: 0.7436 - val_loss: 0.3321 - val_accuracy: 0.4211\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.0130 - accuracy: 0.7480 - val_loss: 0.3232 - val_accuracy: 0.4035\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0120 - accuracy: 0.7788 - val_loss: 0.3207 - val_accuracy: 0.4123\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0085 - accuracy: 0.7911 - val_loss: 0.3152 - val_accuracy: 0.4123\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0071 - accuracy: 0.7366 - val_loss: 0.3134 - val_accuracy: 0.4561\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0077 - accuracy: 0.7626 - val_loss: 0.3098 - val_accuracy: 0.4035\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0054 - accuracy: 0.7789 - val_loss: 0.3074 - val_accuracy: 0.3947\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0051 - accuracy: 0.7652 - val_loss: 0.3086 - val_accuracy: 0.4035\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0044 - accuracy: 0.7985 - val_loss: 0.3243 - val_accuracy: 0.3596\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0039 - accuracy: 0.7699 - val_loss: 0.3132 - val_accuracy: 0.4035\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0039 - accuracy: 0.7567 - val_loss: 0.3217 - val_accuracy: 0.4298\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0036 - accuracy: 0.7834 - val_loss: 0.3357 - val_accuracy: 0.4035\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0032 - accuracy: 0.7568 - val_loss: 0.3344 - val_accuracy: 0.4211\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0033 - accuracy: 0.7779 - val_loss: 0.3411 - val_accuracy: 0.4123\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0039 - accuracy: 0.7101 - val_loss: 0.3568 - val_accuracy: 0.4035\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0020 - accuracy: 0.7568 - val_loss: 0.3623 - val_accuracy: 0.4123\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0025 - accuracy: 0.7939 - val_loss: 0.4246 - val_accuracy: 0.3509\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0021 - accuracy: 0.7723 - val_loss: 0.3980 - val_accuracy: 0.3860\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0025 - accuracy: 0.8050 - val_loss: 0.4067 - val_accuracy: 0.3772\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0020 - accuracy: 0.7977 - val_loss: 0.4262 - val_accuracy: 0.3772\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0015 - accuracy: 0.7870 - val_loss: 0.4223 - val_accuracy: 0.3860\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0016 - accuracy: 0.7525 - val_loss: 0.4422 - val_accuracy: 0.3772\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0015 - accuracy: 0.7312 - val_loss: 0.4542 - val_accuracy: 0.4035\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0012 - accuracy: 0.7725 - val_loss: 0.4582 - val_accuracy: 0.3947\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0014 - accuracy: 0.7380 - val_loss: 0.4603 - val_accuracy: 0.4035\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.0015 - accuracy: 0.7837 - val_loss: 0.4866 - val_accuracy: 0.4123\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0012 - accuracy: 0.7315 - val_loss: 0.4959 - val_accuracy: 0.4035\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 8.7575e-04 - accuracy: 0.7776 - val_loss: 0.4990 - val_accuracy: 0.3947\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0010 - accuracy: 0.7981 - val_loss: 0.5140 - val_accuracy: 0.3947\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0013 - accuracy: 0.7993 - val_loss: 0.5180 - val_accuracy: 0.3860\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 8.4010e-04 - accuracy: 0.7954 - val_loss: 0.5215 - val_accuracy: 0.3860\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 9.9591e-04 - accuracy: 0.8175 - val_loss: 0.5167 - val_accuracy: 0.3772\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0010 - accuracy: 0.7855 - val_loss: 0.5290 - val_accuracy: 0.3947\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 6.7141e-04 - accuracy: 0.7649 - val_loss: 0.5392 - val_accuracy: 0.3860\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0011 - accuracy: 0.7470 - val_loss: 0.5390 - val_accuracy: 0.3772\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 8.3000e-04 - accuracy: 0.7684 - val_loss: 0.5613 - val_accuracy: 0.3684\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 5.3823e-04 - accuracy: 0.8002 - val_loss: 0.5493 - val_accuracy: 0.3772\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 7.8454e-04 - accuracy: 0.7440 - val_loss: 0.5434 - val_accuracy: 0.3947\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5434 - accuracy: 0.3947\n",
      "[0.5433995723724365, 0.3947368562221527]\n"
     ]
    }
   ],
   "source": [
    "hist = sequential_tokenized.fit(X_train_tokens, y_train, epochs=50, verbose=True, validation_data=(X_test_tokens, y_test), batch_size=24)\n",
    "y_pred = sequential_tokenized.predict(X_test_tokens)\n",
    "\n",
    "print(sequential_tokenized.evaluate(X_test_tokens, y_test))\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_tokenized_conv\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_11 (Embedding)     (None, 1134, 200)         1044200   \n_________________________________________________________________\nconv1d_10 (Conv1D)           (None, 1132, 256)         153856    \n_________________________________________________________________\nbatch_normalization_26 (Batc (None, 1132, 256)         1024      \n_________________________________________________________________\nleaky_re_lu_26 (LeakyReLU)   (None, 1132, 256)         0         \n_________________________________________________________________\nglobal_max_pooling1d_11 (Glo (None, 256)               0         \n_________________________________________________________________\ndense_30 (Dense)             (None, 10)                2570      \n=================================================================\nTotal params: 1,201,650\nTrainable params: 1,201,138\nNon-trainable params: 512\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequential_tokenized_conv = Sequential(name='sequential_tokenized_conv')\n",
    "# sequential_tokenized.add(Input(shape=X_train_tokens.shape[1]))\n",
    "sequential_tokenized_conv.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=200, input_length=max_length))\n",
    "sequential_tokenized_conv.add(Conv1D(256, 3, padding='valid'))\n",
    "sequential_tokenized_conv.add(BatchNormalization())\n",
    "sequential_tokenized_conv.add(LeakyReLU())\n",
    "sequential_tokenized_conv.add(GlobalMaxPooling1D())\n",
    "# sequential_tokenized.add(Conv1D(32, 11, activation='relu'))\n",
    "# sequential_tokenized_conv.add(Dense(250))\n",
    "# sequential_tokenized_conv.add(BatchNormalization())\n",
    "# sequential_tokenized_conv.add(LeakyReLU())\n",
    "# sequential_tokenized.add(Conv1D(64, 7, activation='relu'))\n",
    "# sequential_tokenized_conv.add(Dense(100))\n",
    "# sequential_tokenized_conv.add(BatchNormalization())\n",
    "# sequential_tokenized_conv.add(LeakyReLU())\n",
    "# sequential_tokenized.add(Dropout(.2))\n",
    "sequential_tokenized_conv.add(Dense(len(mlb.classes_), activation='sigmoid'))\n",
    "\n",
    "sequential_tokenized_conv.compile(\n",
    "    loss=BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=Nadam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "sequential_tokenized_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - 5s 219ms/step - loss: 0.6294 - accuracy: 0.2054 - val_loss: 0.6869 - val_accuracy: 0.1842\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 4s 211ms/step - loss: 0.1872 - accuracy: 0.6537 - val_loss: 0.6735 - val_accuracy: 0.3246\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 4s 214ms/step - loss: 0.0845 - accuracy: 0.7779 - val_loss: 0.6606 - val_accuracy: 0.3860\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 4s 212ms/step - loss: 0.0486 - accuracy: 0.7764 - val_loss: 0.6437 - val_accuracy: 0.4211\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 4s 214ms/step - loss: 0.0321 - accuracy: 0.7533 - val_loss: 0.6290 - val_accuracy: 0.4211\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 4s 211ms/step - loss: 0.0212 - accuracy: 0.7612 - val_loss: 0.6131 - val_accuracy: 0.4386\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 4s 210ms/step - loss: 0.0163 - accuracy: 0.7587 - val_loss: 0.5975 - val_accuracy: 0.4386\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 4s 208ms/step - loss: 0.0137 - accuracy: 0.7471 - val_loss: 0.5790 - val_accuracy: 0.4211\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 4s 208ms/step - loss: 0.0111 - accuracy: 0.7537 - val_loss: 0.5634 - val_accuracy: 0.4211\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 4s 206ms/step - loss: 0.0101 - accuracy: 0.7356 - val_loss: 0.5439 - val_accuracy: 0.4123\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 4s 208ms/step - loss: 0.0083 - accuracy: 0.7325 - val_loss: 0.5268 - val_accuracy: 0.4123\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 4s 206ms/step - loss: 0.0074 - accuracy: 0.7470 - val_loss: 0.5081 - val_accuracy: 0.4123\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 4s 219ms/step - loss: 0.0064 - accuracy: 0.7814 - val_loss: 0.4889 - val_accuracy: 0.4211\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 4s 212ms/step - loss: 0.0056 - accuracy: 0.7166 - val_loss: 0.4703 - val_accuracy: 0.4123\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 4s 213ms/step - loss: 0.0052 - accuracy: 0.7240 - val_loss: 0.4508 - val_accuracy: 0.4211\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 4s 212ms/step - loss: 0.0044 - accuracy: 0.7502 - val_loss: 0.4321 - val_accuracy: 0.4123\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 4s 210ms/step - loss: 0.0038 - accuracy: 0.7661 - val_loss: 0.4139 - val_accuracy: 0.4211\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 4s 214ms/step - loss: 0.0037 - accuracy: 0.7422 - val_loss: 0.3959 - val_accuracy: 0.4211\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 4s 207ms/step - loss: 0.0031 - accuracy: 0.7428 - val_loss: 0.3791 - val_accuracy: 0.4211\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 4s 224ms/step - loss: 0.0029 - accuracy: 0.7463 - val_loss: 0.3631 - val_accuracy: 0.4211\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 4s 215ms/step - loss: 0.0026 - accuracy: 0.7348 - val_loss: 0.3482 - val_accuracy: 0.4211\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 4s 218ms/step - loss: 0.0025 - accuracy: 0.7321 - val_loss: 0.3357 - val_accuracy: 0.4386\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 4s 218ms/step - loss: 0.0023 - accuracy: 0.7263 - val_loss: 0.3247 - val_accuracy: 0.4211\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 4s 216ms/step - loss: 0.0025 - accuracy: 0.7071 - val_loss: 0.3163 - val_accuracy: 0.4386\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 4s 214ms/step - loss: 0.0020 - accuracy: 0.7154 - val_loss: 0.3099 - val_accuracy: 0.4386\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 4s 216ms/step - loss: 0.0018 - accuracy: 0.7602 - val_loss: 0.3063 - val_accuracy: 0.4386\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 4s 221ms/step - loss: 0.0018 - accuracy: 0.7416 - val_loss: 0.3048 - val_accuracy: 0.4386\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 4s 217ms/step - loss: 0.0016 - accuracy: 0.7636 - val_loss: 0.3057 - val_accuracy: 0.4386\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 4s 217ms/step - loss: 0.0016 - accuracy: 0.7699 - val_loss: 0.3088 - val_accuracy: 0.4386\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 4s 224ms/step - loss: 0.0014 - accuracy: 0.6951 - val_loss: 0.3144 - val_accuracy: 0.4386\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 4s 221ms/step - loss: 0.0013 - accuracy: 0.7536 - val_loss: 0.3214 - val_accuracy: 0.4386\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 4s 221ms/step - loss: 0.0013 - accuracy: 0.7364 - val_loss: 0.3293 - val_accuracy: 0.4386\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 4s 229ms/step - loss: 0.0012 - accuracy: 0.7794 - val_loss: 0.3388 - val_accuracy: 0.4386\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 4s 227ms/step - loss: 0.0012 - accuracy: 0.7239 - val_loss: 0.3487 - val_accuracy: 0.4386\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 4s 221ms/step - loss: 0.0011 - accuracy: 0.7528 - val_loss: 0.3596 - val_accuracy: 0.4386\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 4s 227ms/step - loss: 0.0011 - accuracy: 0.6844 - val_loss: 0.3700 - val_accuracy: 0.4386\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 4s 223ms/step - loss: 0.0010 - accuracy: 0.7418 - val_loss: 0.3809 - val_accuracy: 0.4474\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 4s 227ms/step - loss: 0.0010 - accuracy: 0.7225 - val_loss: 0.3905 - val_accuracy: 0.4474\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 4s 220ms/step - loss: 8.6150e-04 - accuracy: 0.7547 - val_loss: 0.4005 - val_accuracy: 0.4474\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 4s 221ms/step - loss: 8.7373e-04 - accuracy: 0.7297 - val_loss: 0.4098 - val_accuracy: 0.4474\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 4s 218ms/step - loss: 8.2226e-04 - accuracy: 0.7338 - val_loss: 0.4186 - val_accuracy: 0.4474\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 4s 220ms/step - loss: 7.8968e-04 - accuracy: 0.7308 - val_loss: 0.4261 - val_accuracy: 0.4474\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 4s 220ms/step - loss: 7.4060e-04 - accuracy: 0.7399 - val_loss: 0.4342 - val_accuracy: 0.4474\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 4s 221ms/step - loss: 7.0917e-04 - accuracy: 0.7550 - val_loss: 0.4410 - val_accuracy: 0.4474\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 4s 220ms/step - loss: 6.9157e-04 - accuracy: 0.7243 - val_loss: 0.4466 - val_accuracy: 0.4561\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 4s 218ms/step - loss: 6.1428e-04 - accuracy: 0.7752 - val_loss: 0.4522 - val_accuracy: 0.4561\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 4s 221ms/step - loss: 6.4105e-04 - accuracy: 0.7412 - val_loss: 0.4572 - val_accuracy: 0.4561\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 4s 227ms/step - loss: 6.0920e-04 - accuracy: 0.7440 - val_loss: 0.4617 - val_accuracy: 0.4561\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 4s 222ms/step - loss: 5.5776e-04 - accuracy: 0.7457 - val_loss: 0.4654 - val_accuracy: 0.4561\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 4s 218ms/step - loss: 5.3942e-04 - accuracy: 0.7150 - val_loss: 0.4700 - val_accuracy: 0.4561\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.4700 - accuracy: 0.4561\n",
      "[0.47002243995666504, 0.45614033937454224]\n"
     ]
    }
   ],
   "source": [
    "hist = sequential_tokenized_conv.fit(X_train_tokens, y_train, epochs=50, verbose=True, validation_data=(X_test_tokens, y_test), batch_size=24)\n",
    "y_pred = sequential_tokenized_conv.predict(X_test_tokens)\n",
    "\n",
    "print(sequential_tokenized_conv.evaluate(X_test_tokens, y_test))\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential_tokenized_lstm = Sequential(name='sequential_tokenized_lstm')\n",
    "# sequential_tokenized.add(Input(shape=X_train_tokens.shape[1]))\n",
    "# sequential_tokenized_lstm.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_length))\n",
    "# sequential_tokenized.add(Flatten())\n",
    "# sequential_tokenized_lstm.add(Conv1D(256, 7, padding='valid'))\n",
    "# sequential_tokenized_lstm.add(BatchNormalization())\n",
    "# sequential_tokenized_lstm.add(LeakyReLU())\n",
    "# sequential_tokenized_lstm.add(Conv1D(512, 5))\n",
    "# sequential_tokenized_lstm.add(BatchNormalization())\n",
    "# sequential_tokenized_lstm.add(LeakyReLU())\n",
    "# sequential_tokenized_lstm.add(GlobalMaxPooling1D())\n",
    "# sequential_tokenized.add(Conv1D(32, 11, activation='relu'))\n",
    "# sequential_tokenized_lstm.add(Dense(500))\n",
    "# sequential_tokenized_lstm.add(BatchNormalization())\n",
    "# sequential_tokenized_lstm.add(LeakyReLU())\n",
    "# sequential_tokenized.add(Conv1D(64, 7, activation='relu'))\n",
    "# sequential_tokenized_lstm.add(Dense(100))\n",
    "# sequential_tokenized_lstm.add(BatchNormalization())\n",
    "# sequential_tokenized_lstm.add(LeakyReLU())\n",
    "# sequential_tokenized.add(Dropout(.2))\n",
    "# sequential_tokenized_lstm.add(Dense(len(mlb.classes_), activation='sigmoid'))\n",
    "\n",
    "# sequential_tokenized_lstm.compile(\n",
    "#     loss=BinaryCrossentropy(from_logits=True),\n",
    "#     optimizer=Nadam(learning_rate=LEARNING_RATE),\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# sequential_tokenized_lstm.summary()"
   ]
  },
  {
   "source": [
    "### Sequential -- TF-IDF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TF-IDF\nX: (454, 53167) | (114, 53167)\ny: (454, 10) | (114, 10)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english', strip_accents='ascii', ngram_range=(1,3))\n",
    "tfidf.fit(X)\n",
    "X_train_tfidf = tfidf.transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "X_train_tfidf.sort_indices()\n",
    "X_test_tfidf.sort_indices()\n",
    "\n",
    "print(f'TF-IDF\\nX: {X_train_tfidf.shape} | {X_test_tfidf.shape}\\ny: {y_train.shape} | {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "53167"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "len(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_tfidf\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_50 (Dense)             (None, 50)                2658400   \n_________________________________________________________________\ndense_51 (Dense)             (None, 10)                510       \n=================================================================\nTotal params: 2,658,910\nTrainable params: 2,658,910\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequential_tfidf = Sequential(name='sequential_tfidf')\n",
    "sequential_tfidf.add(Input(shape=X_train_tfidf.shape[1]))\n",
    "# sequential_tfidf.add(Embedding(input_dim=X_train_tokens.shape[1], output_dim=200))\n",
    "# sequential_tfidf.add(Dense(1000))\n",
    "# sequential_counts.add(BatchNormalization())\n",
    "# sequential_counts.add(LeakyReLU())\n",
    "# sequential_tfidf.add(Conv1D(32, 11, activation='relu'))\n",
    "# sequential_tfidf.add(Dense(250))\n",
    "# sequential_counts.add(BatchNormalization())\n",
    "# sequential_counts.add(LeakyReLU())\n",
    "# sequential_tfidf.add(Conv1D(64, 7, activation='relu'))\n",
    "sequential_tfidf.add(Dense(50))\n",
    "sequential_counts.add(BatchNormalization())\n",
    "sequential_counts.add(LeakyReLU())\n",
    "# sequential_tfidf.add(Dropout(.5))\n",
    "sequential_tfidf.add(Dense(len(mlb.classes_), activation='sigmoid'))\n",
    "\n",
    "sequential_tfidf.compile(\n",
    "    loss=BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=Nadam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "sequential_tfidf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.6855 - accuracy: 0.1346 - val_loss: 0.6563 - val_accuracy: 0.2895\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.6204 - accuracy: 0.4697 - val_loss: 0.6002 - val_accuracy: 0.2807\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.5308 - accuracy: 0.3098 - val_loss: 0.5406 - val_accuracy: 0.2719\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4432 - accuracy: 0.2695 - val_loss: 0.4923 - val_accuracy: 0.2807\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3799 - accuracy: 0.3178 - val_loss: 0.4589 - val_accuracy: 0.2807\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3325 - accuracy: 0.4048 - val_loss: 0.4370 - val_accuracy: 0.2807\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2920 - accuracy: 0.4728 - val_loss: 0.4217 - val_accuracy: 0.2807\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2615 - accuracy: 0.4694 - val_loss: 0.4097 - val_accuracy: 0.2895\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2323 - accuracy: 0.6022 - val_loss: 0.4003 - val_accuracy: 0.2982\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2073 - accuracy: 0.6396 - val_loss: 0.3929 - val_accuracy: 0.3158\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1827 - accuracy: 0.6881 - val_loss: 0.3865 - val_accuracy: 0.3158\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.1648 - accuracy: 0.6689 - val_loss: 0.3814 - val_accuracy: 0.3246\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1487 - accuracy: 0.7114 - val_loss: 0.3774 - val_accuracy: 0.3333\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.1325 - accuracy: 0.7132 - val_loss: 0.3743 - val_accuracy: 0.3509\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.1188 - accuracy: 0.6834 - val_loss: 0.3720 - val_accuracy: 0.3509\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1022 - accuracy: 0.7314 - val_loss: 0.3704 - val_accuracy: 0.3596\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0958 - accuracy: 0.7384 - val_loss: 0.3693 - val_accuracy: 0.3684\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0842 - accuracy: 0.7426 - val_loss: 0.3688 - val_accuracy: 0.3684\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0751 - accuracy: 0.7217 - val_loss: 0.3690 - val_accuracy: 0.3684\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0698 - accuracy: 0.7195 - val_loss: 0.3695 - val_accuracy: 0.3772\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0645 - accuracy: 0.7261 - val_loss: 0.3703 - val_accuracy: 0.3772\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.0563 - accuracy: 0.6939 - val_loss: 0.3713 - val_accuracy: 0.3860\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0507 - accuracy: 0.7155 - val_loss: 0.3726 - val_accuracy: 0.3860\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0482 - accuracy: 0.7348 - val_loss: 0.3742 - val_accuracy: 0.3860\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0439 - accuracy: 0.7247 - val_loss: 0.3758 - val_accuracy: 0.3860\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0409 - accuracy: 0.7171 - val_loss: 0.3776 - val_accuracy: 0.3860\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0352 - accuracy: 0.7567 - val_loss: 0.3794 - val_accuracy: 0.3860\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0325 - accuracy: 0.7258 - val_loss: 0.3812 - val_accuracy: 0.3860\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0318 - accuracy: 0.7384 - val_loss: 0.3832 - val_accuracy: 0.3860\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0293 - accuracy: 0.7335 - val_loss: 0.3854 - val_accuracy: 0.3860\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0251 - accuracy: 0.7344 - val_loss: 0.3875 - val_accuracy: 0.3860\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0234 - accuracy: 0.7203 - val_loss: 0.3897 - val_accuracy: 0.3860\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0228 - accuracy: 0.6914 - val_loss: 0.3919 - val_accuracy: 0.3860\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0213 - accuracy: 0.7433 - val_loss: 0.3941 - val_accuracy: 0.3860\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0196 - accuracy: 0.7067 - val_loss: 0.3965 - val_accuracy: 0.3947\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0183 - accuracy: 0.7337 - val_loss: 0.3988 - val_accuracy: 0.3947\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0191 - accuracy: 0.7373 - val_loss: 0.4010 - val_accuracy: 0.3947\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0167 - accuracy: 0.7180 - val_loss: 0.4032 - val_accuracy: 0.3947\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0159 - accuracy: 0.7326 - val_loss: 0.4052 - val_accuracy: 0.3947\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0149 - accuracy: 0.7478 - val_loss: 0.4074 - val_accuracy: 0.3947\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0142 - accuracy: 0.7575 - val_loss: 0.4095 - val_accuracy: 0.3947\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0130 - accuracy: 0.7296 - val_loss: 0.4116 - val_accuracy: 0.3947\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0131 - accuracy: 0.7369 - val_loss: 0.4138 - val_accuracy: 0.3947\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0118 - accuracy: 0.7195 - val_loss: 0.4160 - val_accuracy: 0.3947\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0109 - accuracy: 0.7170 - val_loss: 0.4181 - val_accuracy: 0.3947\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0103 - accuracy: 0.7060 - val_loss: 0.4202 - val_accuracy: 0.3947\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0104 - accuracy: 0.7378 - val_loss: 0.4223 - val_accuracy: 0.3947\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0101 - accuracy: 0.7242 - val_loss: 0.4243 - val_accuracy: 0.3947\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0095 - accuracy: 0.7250 - val_loss: 0.4264 - val_accuracy: 0.3947\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0100 - accuracy: 0.7356 - val_loss: 0.4283 - val_accuracy: 0.3947\n",
      "4/4 [==============================] - 0s 962us/step - loss: 0.4283 - accuracy: 0.3947\n",
      "[0.4282691478729248, 0.3947368562221527]\n"
     ]
    }
   ],
   "source": [
    "hist = sequential_tfidf.fit(X_train_tfidf, y_train, epochs=50, verbose=True, validation_data=(X_test_tfidf, y_test), batch_size=32)\n",
    "y_pred = sequential_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "print(sequential_tfidf.evaluate(X_test_tfidf, y_test))\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_tfidf_emb\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_14 (Embedding)     (None, 1134, 200)         10633600  \n_________________________________________________________________\nglobal_max_pooling1d_14 (Glo (None, 200)               0         \n_________________________________________________________________\ndense_54 (Dense)             (None, 250)               50250     \n_________________________________________________________________\nbatch_normalization_40 (Batc (None, 250)               1000      \n_________________________________________________________________\nleaky_re_lu_40 (LeakyReLU)   (None, 250)               0         \n_________________________________________________________________\ndense_55 (Dense)             (None, 10)                2510      \n=================================================================\nTotal params: 10,687,360\nTrainable params: 10,686,860\nNon-trainable params: 500\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequential_tfidf_emb = Sequential(name='sequential_tfidf_emb')\n",
    "sequential_tfidf_emb.add(Embedding(input_dim=len(tfidf.vocabulary_) + 1, output_dim=200, input_length=max_length))\n",
    "sequential_tfidf_emb.add(GlobalMaxPooling1D())\n",
    "# sequential_tokenized.add(Dense(1000))\n",
    "# sequential_tokenized.add(BatchNormalization())\n",
    "# sequential_tokenized.add(LeakyReLU())\n",
    "# sequential_tokenized.add(Dense(500))\n",
    "# sequential_tokenized.add(BatchNormalization())\n",
    "# sequential_tokenized.add(LeakyReLU())\n",
    "sequential_tfidf_emb.add(Dense(250))\n",
    "sequential_tfidf_emb.add(BatchNormalization())\n",
    "sequential_tfidf_emb.add(LeakyReLU())\n",
    "# sequential_tokenized.add(Dense(100))\n",
    "# sequential_tokenized.add(BatchNormalization())\n",
    "# sequential_tokenized.add(LeakyReLU())\n",
    "# sequential_tokenized.add(Dense(50))\n",
    "# sequential_tokenized.add(BatchNormalization())\n",
    "# sequential_tokenized.add(LeakyReLU())\n",
    "sequential_tfidf_emb.add(Dense(len(mlb.classes_), activation='sigmoid'))\n",
    "\n",
    "sequential_tfidf_emb.compile(\n",
    "    loss=BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=Nadam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "sequential_tfidf_emb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "in user code:\n\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:375 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:424 call\n        return self._run_internal_graph(\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:560 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/keras/layers/embeddings.py:196 call\n        out = embedding_ops.embedding_lookup_v2(self.embeddings, inputs)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/ops/embedding_ops.py:394 embedding_lookup_v2\n        return embedding_lookup(params, ids, \"div\", name, max_norm=max_norm)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/ops/embedding_ops.py:322 embedding_lookup\n        return _embedding_lookup_and_transform(\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/ops/embedding_ops.py:134 _embedding_lookup_and_transform\n        ids = ops.convert_to_tensor(ids, name=\"ids\")\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py:163 wrapped\n        return func(*args, **kwargs)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1540 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:339 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:264 constant\n        return _constant_impl(value, dtype, shape, name, verify_shape=False,\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:281 _constant_impl\n        tensor_util.make_tensor_proto(\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py:551 make_tensor_proto\n        raise TypeError(\"Failed to convert object of type %s to Tensor. \"\n\n    TypeError: Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. Contents: SparseTensor(indices=Tensor(\"DeserializeSparse:0\", shape=(None, 2), dtype=int64), values=Tensor(\"sequential_tfidf_emb/embedding_14/Cast:0\", shape=(None,), dtype=int32), dense_shape=Tensor(\"stack:0\", shape=(2,), dtype=int64)). Consider casting elements to a supported type.\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-436a78818ca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequential_tfidf_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequential_tfidf_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequential_tfidf_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(confusion_matrix(y_test, y_pred))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:375 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:424 call\n        return self._run_internal_graph(\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:560 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/keras/layers/embeddings.py:196 call\n        out = embedding_ops.embedding_lookup_v2(self.embeddings, inputs)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/ops/embedding_ops.py:394 embedding_lookup_v2\n        return embedding_lookup(params, ids, \"div\", name, max_norm=max_norm)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/ops/embedding_ops.py:322 embedding_lookup\n        return _embedding_lookup_and_transform(\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/ops/embedding_ops.py:134 _embedding_lookup_and_transform\n        ids = ops.convert_to_tensor(ids, name=\"ids\")\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py:163 wrapped\n        return func(*args, **kwargs)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1540 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:339 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:264 constant\n        return _constant_impl(value, dtype, shape, name, verify_shape=False,\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:281 _constant_impl\n        tensor_util.make_tensor_proto(\n    /Users/Michael/.pyenv/versions/anaconda3-2020.11/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py:551 make_tensor_proto\n        raise TypeError(\"Failed to convert object of type %s to Tensor. \"\n\n    TypeError: Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. Contents: SparseTensor(indices=Tensor(\"DeserializeSparse:0\", shape=(None, 2), dtype=int64), values=Tensor(\"sequential_tfidf_emb/embedding_14/Cast:0\", shape=(None,), dtype=int32), dense_shape=Tensor(\"stack:0\", shape=(2,), dtype=int64)). Consider casting elements to a supported type.\n"
     ]
    }
   ],
   "source": [
    "hist = sequential_tfidf_emb.fit(X_train_tfidf, y_train, epochs=50, verbose=True, validation_data=(X_test_tfidf, y_test), batch_size=32)\n",
    "y_pred = sequential_tfidf_emb.predict(X_test_tfidf)\n",
    "\n",
    "print(sequential_tfidf_emb.evaluate(X_test_tfidf, y_test))\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}